{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8808,  4.7629],\n",
      "        [ 4.8577, 11.9728]], grad_fn=<AddBackward0>)\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from highway import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "input_size = 50\n",
    "x = torch.zeros((2, 2), dtype=torch.float32)\n",
    "model = Highway(2, 0.2)\n",
    "x_word_emb = model(x)\n",
    "print(x_word_emb.size())  # you should see [64, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2509,  2.8514],\n",
      "        [ 4.0343, 10.0390]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 0], [2, 1]], dtype=torch.float32)\n",
    "model = Highway(2, 0)\n",
    "model.linear_proj.weight.data.copy_(torch.tensor([[1, 2], [3, 4]], dtype=torch.float32))\n",
    "model.linear_gate.weight.data.copy_(torch.tensor([[1, 0], [3, 0]], dtype=torch.float32))\n",
    "x_word_emb = model(x)\n",
    "print(x_word_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 0], [2, 1]])\n",
    "W1 = np.array([[1, 2], [3, 4]])\n",
    "b1 = np.array([1, 2])\n",
    "W2 = np.array([[1, 0], [3, 0]])\n",
    "b2 = np.array([1, 0])\n",
    "\n",
    "x_proj = np.maximum(x * W1 + b1, 0)\n",
    "x_gate = sigmoid(x * W2.T + b2)\n",
    "x_highway = x_gate * x_proj + (1 - x_gate) * x\n",
    "print(x_proj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
